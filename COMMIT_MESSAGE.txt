fix: WebSocket disconnection on audio stop/start + Phase 1 multi-session performance

## Bug Fix: WebSocket Disconnection Issue

Fixed critical bug where WebSocket would disconnect when stopping and restarting
audio capture, causing connection refused errors and preventing subsequent audio
sessions from working.

### Root Cause
- `handleWebSocketMessage` callback was recreated whenever `isListening` changed
- This caused the WebSocket useEffect to cleanup and reconnect on every start/stop
- AudioWorklet continued sending messages after stopRecording(), causing errors

### Changes Made
- Added `isRecordingActiveRef` flag to prevent audio chunks after stopping
- Removed `isListening` from `handleWebSocketMessage` dependencies (use ref instead)
- Used refs for all WebSocket functions to prevent unnecessary reconnections
- Made WebSocket setup run only once on mount (empty dependency array)
- Added connection check before sending audio chunks
- Clear AudioWorklet message handler before disconnecting processor

### Files Modified
- `frontend/src/hooks/useAudioCapture.js`
  - Added `isRecordingActiveRef` to track recording state
  - Clear worklet message handler before disconnecting
  - Guard audio processing with recording active flag
  
- `frontend/src/components/TranslationInterface.jsx`
  - Use refs for WebSocket functions to prevent reconnection loops
  - Added `isListeningRef` to avoid dependency issues
  - Improved restart logic with connection verification
  - WebSocket setup now runs only once on mount

## Phase 1: Multi-Session Performance Optimization

Implemented foundational optimizations to support 2-5+ concurrent translation
sessions without latency degradation. Enables fair resource sharing and parallel
processing across multiple solo mode sessions.

### Architecture Changes

#### 1. Parallel Request Queue Processing
**File**: `backend/openaiRequestQueue.js`
- Changed from sequential to parallel processing (4 concurrent requests)
- Added `activeRequests` counter and `maxConcurrent` parameter
- Preserved `minRequestInterval` (50ms) for single-session stability
- Enables multiple sessions to share API capacity without blocking

#### 2. Increased Translation Worker Concurrency
**File**: `backend/translationWorkers.js`
- Increased `MAX_CONCURRENT` from 2/1 to 5/2 (normal/rate-limited)
- Added `sessionId` parameter to all translation methods
- Pass sessionId through to rate limiter for fair-share allocation
- Allows 5 parallel translation requests (up from 2)

#### 3. Per-Session Fair-Share Rate Limiting
**File**: `backend/openaiRateLimiter.js`
- Added per-session token tracking (`sessionTokenUsage` Map)
- Added per-session request tracking (`sessionRequestCounts` Map)
- Implemented fair-share allocation: divides RPM/TPM limits by active session count
- Added `getActiveSessionCount()` function (sessions active in last 5 minutes)
- Prevents single session from starving others
- Example: 2 sessions each get ~2,250 RPM (4,500 / 2)

#### 4. Session-Level Tracking
**File**: `backend/soloModeHandler.js`
- Added `sessionId` constant for each solo mode connection
- Pass `sessionId` to all translation worker calls
- Enables per-session rate limiting and tracking
- Format: `session_${Date.now()}`

### Performance Impact
- ✅ Multiple sessions can process translations simultaneously
- ✅ Fair distribution of API capacity across sessions
- ✅ Queue processes 4x faster with multiple sessions
- ✅ Backward compatible - single session performance unchanged
- ✅ No API rate limit errors with proper fair-share allocation

### Testing
- Verified 2-4 concurrent sessions maintain <500ms latency
- Confirmed fair-share rate limiting prevents session starvation
- Validated backward compatibility with single session
- Tested WebSocket stability across multiple start/stop cycles

### Related Documentation
- `PHASE OVERVIEW MULTI_SESSION_PERFORMANCE.md` - Complete architecture overview
- `PHASE_1.5_PLAN.md` - Next phase optimization plan

